#!/usr/bin/env python3
# vim: set ft=python sts=4 ts=4 sw=4 et:
# BSD 2-clause license. Author: Adam Wojciech Koszek <adam@koszek.com>

# @todo: we should unify the interface for all the models so
# that we use the same OpenAI interface for all the models.

import sys
import json
import time
import datetime
import argparse
import re
import os
from openai import OpenAI
from anthropic import Anthropic
import google.generativeai as genai

# Initialize API clients
openai_client = OpenAI()
anthropic_client = Anthropic()
genai.configure()

def call_openai_model(prompt, model):
    """Calls OpenAI API with the given prompt and model."""
    start_time = time.time()
    response = openai_client.chat.completions.create(
        model=model,
        messages=[{"role": "user", "content": prompt}]
    )
    output_text = response.choices[0].message.content
    end_time = time.time()
    return output_text, start_time, end_time

def call_anthropic_model(prompt, model):
    """Calls Anthropic API with the given prompt and model."""
    start_time = time.time()
    response = anthropic_client.messages.create(
        model=model,
        max_tokens=4096,
        messages=[{"role": "user", "content": prompt}]
    )
    output_text = response.content[0].text
    end_time = time.time()
    return output_text, start_time, end_time

def call_gemini_model(prompt, model):
    """Calls Google's Gemini API with the given prompt and model."""
    start_time = time.time()
    model = genai.GenerativeModel(model)
    response = model.generate_content(prompt)
    output_text = response.text
    end_time = time.time()
    return output_text, start_time, end_time

def call_grok_model(prompt, model):
    """Calls Grok API using OpenAI SDK with x.ai endpoint."""
    start_time = time.time()
    
    # Get API key from environment
    api_key = os.getenv('GROK_API_KEY')
    if not api_key:
        raise ValueError("GROK_API_KEY environment variable is not set")
    
    # Create a new OpenAI client with x.ai endpoint
    grok_client = OpenAI(
        api_key=api_key,
        base_url="https://api.x.ai/v1"
    )
    
    # Call the API using OpenAI SDK
    response = grok_client.chat.completions.create(
        model=model,
        messages=[{"role": "user", "content": prompt}]
    )
    
    output_text = response.choices[0].message.content
    end_time = time.time()
    return output_text, start_time, end_time

def determine_backend(model):
    """Determine which backend to use based on the model name."""
    # OpenAI models
    if re.match(r'gpt-', model):
        return call_openai_model
    # Anthropic models
    elif re.match(r'claude-', model):
        return call_anthropic_model
    # Google models
    elif re.match(r'gemini-', model):
        return call_gemini_model
    # Grok models
    elif re.match(r'grok-', model):
        return call_grok_model
    else:
        return None

def main():
    parser = argparse.ArgumentParser(description="Unified Language Model CLI")
    parser.add_argument("model", type=str, nargs="?", help="Model to use (e.g., gpt-4, claude-3-opus-20240229, gemini-pro, grok-1)")
    args = parser.parse_args()

    # Get the program's basename
    program_name = os.path.basename(sys.argv[0])
    
    # If program name is not "lmt", use it as the model name (removing "lmt-" prefix)
    if program_name != "lmt":
        model = program_name.replace("lmt-", "")
    else:
        # If program name is "lmt", require the model argument
        if not args.model:
            print("Error: Model name must be provided when using 'lmt' command.", file=sys.stderr)
            sys.exit(1)
        model = args.model

    # Determine which backend to use
    backend_func = determine_backend(model)
    if not backend_func:
        print(f"Error: Unknown model '{model}'. Please use a model from OpenAI (gpt-*), Anthropic (claude-*), Google (gemini-*), or Grok (grok-*).", file=sys.stderr)
        sys.exit(1)

    # Read input from stdin
    prompt = sys.stdin.read().strip()
    if not prompt:
        print("Error: No input provided on STDIN.", file=sys.stderr)
        sys.exit(1)

    try:
        # Call the appropriate model
        output, time_sent_at, time_recv_at = backend_func(prompt, model)

        # Print output to STDOUT
        print(output)

        # Generate log filename
        timestamp = datetime.datetime.now().strftime("%Y%m%d-%H%M%S")
        log_filename = f"{timestamp}-{model}.json"

        # Log data
        log_data = {
            "in": {
                "time_sent_at": time_sent_at,
                "prompt": prompt,
                "algo": model
            },
            "out": {
                "time_recv_at": time_recv_at,
                "output": output,
                "algo": model
            }
        }

        with open(log_filename, "w") as log_file:
            json.dump(log_data, log_file, indent=4)

    except Exception as e:
        print(f"Error: {str(e)}", file=sys.stderr)
        sys.exit(1)

if __name__ == "__main__":
    main() 
